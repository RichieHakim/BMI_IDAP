{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65846323",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92846ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda Environment: BMI_IDAP\n"
     ]
    }
   ],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eb1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.manifold\n",
    "import sklearn.cluster\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sparse\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from kymatio.torch import Scattering2D\n",
    "\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a85fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "dir_github = Path(r'D:\\RH_local\\github').resolve()\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"/n/data1/hms/neurobio/sabatini/rich/github_repos/\")\n",
    "# sys.path.append(\"/media/rich/Home_Linux_partition/github_repos/\")\n",
    "sys.path.append(str(dir_github))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from Big_Ugly_ROI_Tracker.multiEps.multiEps_modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880515fd",
   "metadata": {},
   "source": [
    "# Import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bd1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directory to save outputs from this notebook like iscell\n",
    "dir_save = Path(r'D:\\RH_local\\data\\scanimage data\\round 6 experiments\\mouse_1_18\\20220225\\analysis_lastNight').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff413eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220215'),\n",
       " WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220223'),\n",
       " WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220225')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220215'),\n",
       " WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220223')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220215/baseline/suite2p/plane0'),\n",
       " WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220223/exp/suite2p/plane0')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220215/baseline/suite2p/plane0/stat.npy'),\n",
       " WindowsPath('D:/RH_local/data/scanimage data/round 6 experiments/mouse_1_18/20220223/exp/suite2p/plane0/stat.npy')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_allOuterFolders = Path(r\"D:\\RH_local\\data\\scanimage data\\round 6 experiments\\mouse_1_18\").resolve()\n",
    "\n",
    "folders_allSessions = path_helpers.get_numeric_contents(dir_allOuterFolders)[0]\n",
    "\n",
    "# folders_toUse = folders_allSessions[:2]\n",
    "folders_toUse = list(map(folders_allSessions.__getitem__, [0,1]))\n",
    "\n",
    "# dir_allS2pFolders = [dir_allOuterFolders / folder / 'exp' / 'suite2p' / 'plane0' for folder in folders_toUse]\n",
    "\n",
    "dir_allS2pFolders_day0 = [folders_toUse[0] / 'baseline' / 'suite2p' / 'plane0']\n",
    "dir_allS2pFolders_dayN = [dir_allOuterFolders / folder / 'exp' / 'suite2p' / 'plane0' for folder in folders_toUse[1:]]\n",
    "dir_allS2pFolders = dir_allS2pFolders_day0 + dir_allS2pFolders_dayN\n",
    "\n",
    "\n",
    "pathSuffixToStat = \"stat.npy\"\n",
    "pathSuffixToOps = \"ops.npy\"\n",
    "\n",
    "paths_allStat = [path / pathSuffixToStat for path in dir_allS2pFolders]\n",
    "paths_allOps  = [path / pathSuffixToOps for path in dir_allS2pFolders]\n",
    "\n",
    "display(folders_allSessions)\n",
    "display(folders_toUse)\n",
    "display(dir_allS2pFolders)\n",
    "display(paths_allStat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc15dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/RH_local/github/GCaMP_ROI_classifier/End_User/simclr-models/ResNet18_simCLR_model_202112078_EOD_transfmod=efficient.pth')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/RH_local/github/GCaMP_ROI_classifier/End_User/simclr-models/ResNet18_simCLR_model_202112078_EOD_transfmod=efficient')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pref_use_NN_distances = True\n",
    "\n",
    "## NN fileNames\n",
    "fileName_NN_pth = 'ResNet18_simCLR_model_202112078_EOD_transfmod=efficient.pth' # name of pth file in dir_NNmodels directory\n",
    "fileName_NN_py  = 'ResNet18_simCLR_model_202112078_EOD_transfmod=efficient' # EXCLUDE THE .PY AT THE END. name of py file in dir_NNmodels directory.\n",
    "\n",
    "## Directories of Classifier stuff\n",
    "dir_GRC_repo = dir_github / 'GCaMP_ROI_classifier'\n",
    "dir_GRC_EndUser = dir_GRC_repo / 'End_User'\n",
    "dir_NNmodels = dir_GRC_EndUser / 'simclr-models'\n",
    "dir_GRC_util = dir_GRC_repo / 'new_stuff'\n",
    "\n",
    "## Paths to NN and LR classifiers\n",
    "path_NN_pth = dir_NNmodels / fileName_NN_pth\n",
    "path_NN_py = dir_NNmodels / fileName_NN_py\n",
    "\n",
    "display(path_NN_pth)\n",
    "display(path_NN_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e238f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(dir_NNmodels))\n",
    "sys.path.append(str(dir_github))\n",
    "sys.path.append(str(dir_GRC_util))\n",
    "sys.path.append(str(dir_GRC_EndUser))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import util\n",
    "import simclr_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d4dcc",
   "metadata": {},
   "source": [
    "# Settings (global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f800d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_GPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273be372",
   "metadata": {},
   "source": [
    "# Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c95cb4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\RH_local\\\\data\\\\scanimage data\\\\round 6 experiments\\\\mouse_1_18\\\\20220223\\\\baseline\\\\suite2p\\\\plane0\\\\ops.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## select and enhance images for registration\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m ops \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mload(path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[()] \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths_allOps]\n\u001b[0;32m      5\u001b[0m meanIms \u001b[38;5;241m=\u001b[39m [ops[ii][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeanImgE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ops))]\n\u001b[0;32m      6\u001b[0m meanIms \u001b[38;5;241m=\u001b[39m apply_CLAHE(meanIms, clipLimit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## select and enhance images for registration\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m ops \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[()] \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths_allOps]\n\u001b[0;32m      5\u001b[0m meanIms \u001b[38;5;241m=\u001b[39m [ops[ii][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeanImgE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ops))]\n\u001b[0;32m      6\u001b[0m meanIms \u001b[38;5;241m=\u001b[39m apply_CLAHE(meanIms, clipLimit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\BMI_IDAP\\lib\\site-packages\\numpy\\lib\\npyio.py:407\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    405\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    408\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\RH_local\\\\data\\\\scanimage data\\\\round 6 experiments\\\\mouse_1_18\\\\20220223\\\\baseline\\\\suite2p\\\\plane0\\\\ops.npy'"
     ]
    }
   ],
   "source": [
    "## select and enhance images for registration\n",
    "\n",
    "ops = [np.load(path, allow_pickle=True)[()] for path in paths_allOps]\n",
    "\n",
    "meanIms = [ops[ii]['meanImgE'] for ii in range(len(ops))]\n",
    "meanIms = apply_CLAHE(meanIms, clipLimit=40)\n",
    "\n",
    "frame_height = meanIms[0].shape[0]\n",
    "frame_width = meanIms[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5afa016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "display_toggle_image_stack(meanIms, clim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f07b47",
   "metadata": {},
   "source": [
    "## Make spatial_footprints\n",
    "- Make a lazy list of all the spatial_footprints\n",
    "- Convert spatial footprints to a sparse array (`ROIs_aligned`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_all = import_and_convert_to_CellReg_spatialFootprints(paths_allStat, frame_height=frame_height, frame_width=frame_width, dtype=np.float32)\n",
    "\n",
    "ROIs_aligned, FOVs_aligned, flows = register_ROIs(meanIms[0], meanIms, sf_all, return_sparse=True, normalize=True)\n",
    "\n",
    "n_roi_per_sesh = [sfs.shape[0] for sfs in ROIs_aligned]\n",
    "n_roi_all = np.sum(n_roi_per_sesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b842b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## remove NaNs from ROIs\n",
    "for ii in range(len(ROIs_aligned)):\n",
    "    ROIs_aligned[ii].data[np.isnan(ROIs_aligned[ii].data)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d154e",
   "metadata": {},
   "source": [
    "Check to make sure the FOVs look aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d76a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_toggle_image_stack(FOVs_aligned, clim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f02156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_toggle_image_stack([rois.multiply( rois.max(1).power(-1) ).sum(0).reshape(frame_height, frame_width) for rois in ROIs_aligned], clim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b4d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_toggle_2channel_image_stack(flows, clim=(-4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce87c7",
   "metadata": {},
   "source": [
    "## Blur ROIs (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e10bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## only needed if convolving ROIs and/or using neural net outputs for distance matrix\n",
    "pref_blurROIs = False\n",
    "DEVICE_blur = torch_helpers.set_device(use_GPU=use_GPU) # define torch device to use. either 'cpu', 'cuda', number, or something else. See torch_helpers.set_device()\n",
    "\n",
    "if pref_blurROIs == True:\n",
    "    kernel_size = 7 # Edge length of kernel image. Make odd number.\n",
    "    kernel_sigma = 1 # sigma of 2D gaussian kernel\n",
    "    kernel = featurization.gaussian_kernel_2D(center=(kernel_size//2, kernel_size//2), image_size=(kernel_size, kernel_size), sig=kernel_sigma)\n",
    "    kernel = kernel / kernel.sum()\n",
    "\n",
    "    ## show the kernel\n",
    "    plt.figure()\n",
    "    plt.imshow(kernel);\n",
    "    plt.title('gaussian kernel')\n",
    "    \n",
    "    ROIs_aligned_blur = [batch_2D_sparse_convolution(\n",
    "        images=rois, \n",
    "        kernel=kernel,\n",
    "        image_shape=(frame_height, frame_width),\n",
    "        num_batches=10,\n",
    "        device=DEVICE_blur,\n",
    "    ) for rois in tqdm(ROIs_aligned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de30e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_toggle_image_stack([ROIs.sum(0).reshape(frame_height, frame_width) for ROIs in ROIs_aligned_blur])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163a450",
   "metadata": {},
   "source": [
    "## Neural network embedding distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_all_cropped = util.import_multiple_stat_files(\n",
    "    paths_statFiles=paths_allStat, \n",
    "#     dir_statFiles=None,\n",
    "#     fileNames_statFiles=None,\n",
    "    out_height_width=[36,36], \n",
    "    max_footprint_width=441, \n",
    "    plot_pref=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d38a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_model = torch_helpers.set_device(use_GPU=use_GPU)\n",
    "\n",
    "model, model_module = import_pth_model(path_NN_pth, fileName_NN_py)\n",
    "\n",
    "data = np.concatenate(sf_all_cropped, axis=0)\n",
    "\n",
    "# Create Data Sets / Data Loaders\n",
    "dataset, dataloader = model_module.get_dataset_dataloader(data, batch_size=64, device=device_model) ## TODO: Troubleshoot the runtime on this\n",
    "\n",
    "# Get Model Latents\n",
    "latents = simclr_helpers.dataloader_to_latents(dataloader, model.to(device_model), DEVICE=device_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd9dd3",
   "metadata": {},
   "source": [
    "## Scattering wavelet embedding distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c08c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_model = torch_helpers.set_device(use_GPU=use_GPU)\n",
    "\n",
    "scattering = Scattering2D(J=2, L=8, shape=sf_all_cropped[0].shape[-2:])\n",
    "if use_GPU:\n",
    "    scattering = scattering.cuda()\n",
    "\n",
    "latents_swt = torch.cat([get_latents_swt(sfs, scattering.cuda(), device_model).cpu() for sfs in sf_all_cropped], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed09926",
   "metadata": {},
   "source": [
    "## Make blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06410899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame_height=FOVs_aligned[0].shape[0]\n",
    "frame_width=FOVs_aligned[0].shape[1]\n",
    "block_height=100\n",
    "block_width=100\n",
    "overlapping_width_Multiplier=0.0\n",
    "outer_block_height=150\n",
    "outer_block_width=150\n",
    "clamp_outer_block_to_frame=True\n",
    "\n",
    "inner_blocks, outer_blocks, centers = make_block_batches(\n",
    "    frame_height=frame_height,\n",
    "    frame_width=frame_width,\n",
    "    block_height=block_height,\n",
    "    block_width=block_width,\n",
    "    overlapping_width_Multiplier=overlapping_width_Multiplier,\n",
    "    outer_block_height=outer_block_height,\n",
    "    outer_block_width=outer_block_width,\n",
    "    clamp_outer_block_to_frame=clamp_outer_block_to_frame\n",
    ")\n",
    "n_blocks = len(inner_blocks)\n",
    "# display(inner_blocks)\n",
    "# display(outer_blocks)\n",
    "print(f'number of blocks: {n_blocks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b793d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_blocks(inner_blocks, outer_blocks, frame_height=512, frame_width=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74498fc",
   "metadata": {},
   "source": [
    "## t-SNE parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = sklearn.neighbors.NearestNeighbors(\n",
    "#         n_neighbors=100,  ## currently using min(sf_block_flat.shape[0], max_n_neighbors)\n",
    "#     radius=1.0, \n",
    "    algorithm='auto',\n",
    "    leaf_size=30, \n",
    "    metric='manhattan',\n",
    "    p=1,\n",
    "#     metric_params=None, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "tsne = sklearn.manifold.TSNE(\n",
    "    n_components=2,\n",
    "#     perplexity=30.0,\n",
    "    early_exaggeration=12.0,\n",
    "    learning_rate='auto',\n",
    "#     learning_rate=,\n",
    "    n_iter=1000,\n",
    "    n_iter_without_progress=300,\n",
    "    min_grad_norm=1e-07,\n",
    "    metric='precomputed',\n",
    "    init='random',\n",
    "    verbose=0,\n",
    "    random_state=None,\n",
    "#     method='barnes_hut',\n",
    "    method='exact',\n",
    "    angle=0.8,\n",
    "    n_jobs=-1,\n",
    "    square_distances=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720fc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT PARAMETER: K-NEAREST NEIGHBORS ####\n",
    "## Lower this to improve speed, but sacrifice some quality. \n",
    "## Choose a number that is > ~ the largest number of ROIs you think a single ROI might have any overlap with.\n",
    "## For most datasets, values around 200 should give high quality results.\n",
    "## Max value is 1023.\n",
    "## Value must be > 3*perplexity.\n",
    "\n",
    "max_n_neighbors = 100\n",
    "max_perplexity = 10\n",
    "\n",
    "##################################################\n",
    "\n",
    "\n",
    "####### Other Parameters #######\n",
    "\n",
    "## This parameter determines how 'binary'-looking masks are\n",
    "## Small values = more binary. Large values weight bright pixels more\n",
    "## mask_scaled = mask ** mask_power\n",
    "mask_power = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4dd9c",
   "metadata": {},
   "source": [
    "## Embed ROIs in t-SNE space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8fa40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx_roi_cat = np.concatenate([np.arange(sfs.shape[0]) for sfs in ROIs_aligned]) # indices of each ROI concatenated together\n",
    "idx_roi_session = np.concatenate([np.ones(sfs.shape[0])*ii for ii,sfs in enumerate(ROIs_aligned)])\n",
    "\n",
    "if pref_blurROIs:\n",
    "# if False:\n",
    "    ROIs_toUse = ROIs_aligned_blur\n",
    "else:\n",
    "    ROIs_toUse = ROIs_aligned\n",
    "\n",
    "block_rois_raw = []\n",
    "for i_block in tqdm(range(n_blocks)):\n",
    "# for i_block in tqdm([10]):\n",
    "    block_rois_raw.append(\n",
    "        embed_ROIs(\n",
    "            outer_blocks,\n",
    "            inner_blocks,\n",
    "            ROIs_toUse,\n",
    "            frame_height,\n",
    "            frame_width,\n",
    "            idx_roi_session,\n",
    "            tsne,\n",
    "            i_block,\n",
    "            mask_power,\n",
    "            max_n_neighbors,\n",
    "            pref_use_NN_distances,\n",
    "            latents,\n",
    "            latents_swt,\n",
    "            max_perplexity\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386f00d",
   "metadata": {},
   "source": [
    "### Visualize t-SNE and test clustering parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ae7aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "block_toUse = 40\n",
    "min_samples = 2\n",
    "max_samples = 2 # for use within this cell only (visualization and titrating eps value). Set to None to speed up visualization\n",
    "\n",
    "embeddings = block_rois_raw[block_toUse]['embeddings']\n",
    "    \n",
    "display_clustering_widget(embeddings, min_samples, max_samples=max_samples, min_slider=0.01, max_slider=5, start_slider=1.0, single_color=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28dcd29",
   "metadata": {},
   "source": [
    "## Set clustering parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b210d7d",
   "metadata": {},
   "source": [
    "- tune `eps_values` and to include desired range of eps values\n",
    "- set `min_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a72340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_values = np.arange(0.4, 3.0, 0.2)\n",
    "eps_values = np.array([0.9, 1.1, 1.3, 1.6])\n",
    "min_samples = 2\n",
    "dbscan_objs = [sklearn.cluster.DBSCAN(\n",
    "        eps=eps,\n",
    "        min_samples=min_samples, \n",
    "#         metric='manhattan',\n",
    "        metric_params=None, \n",
    "        algorithm='auto',\n",
    "        leaf_size=30, \n",
    "        p=2, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "              for eps in eps_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_rois = run_clustering_sweep(block_rois_raw, dbscan_objs, idx_roi_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b39144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_helpers.simple_save(block_rois, '/media/rich/bigSSD/analysis_data/mouse 2_6/multiday_alignment/block_rois_valerio1_distal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_rois = pickle_helpers.simple_load('/media/rich/bigSSD/analysis_data/mouse 2_6/multiday_alignment/block_rois.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8c71d",
   "metadata": {},
   "source": [
    "the following block should be able to get folded into the main loop above. Just need to break the list comprehension up into a real for loop and index into both the inner and outer blocks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b23364dc",
   "metadata": {},
   "source": [
    "bool_roi_outerBlock_cat = np.stack([block['boolCat_ROI_inOuterBlock'] for block in block_rois])\n",
    "bool_roi_innerBlock_cat = np.stack([block['boolCat_ROI_inInnerBlock'] for block in block_rois])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3951af",
   "metadata": {},
   "source": [
    "## Get ROI properties\n",
    "1. Cluster size (n_roi in cluster)\n",
    "2. Cluster mean of distances (mean of differences between spatial footprints)\n",
    "3. Cluster std of distances (variance of differences between spatial footprints)\n",
    "4. Cluster max of distances (max of differences between spatial footprints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6aa5f",
   "metadata": {},
   "source": [
    "Heuristic to determine which block to trust for each ROI:\n",
    "\n",
    "- for each block, determine how many rois are a part of each cluster\n",
    "- for each roi, determine how many 'neighbor' rois are in it's cluster\n",
    "\n",
    "\n",
    "- then, for each roi, trust the block that clustered it with the greatest number of ROIs that wasn't too many (ranges between a user defined range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb539642",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs_aligned_cat = scipy.sparse.vstack(ROIs_aligned)\n",
    "ROIs_aligned_cat_scaled = ROIs_aligned_cat\n",
    "ROIs_aligned_cat_scaled = ROIs_aligned_cat_scaled.power(mask_power)\n",
    "ROIs_aligned_cat_scaled = ROIs_aligned_cat_scaled.multiply( 1 / ROIs_aligned_cat_scaled.sum(1) )\n",
    "ROIs_aligned_cat_scaled = scipy.sparse.csr_matrix(ROIs_aligned_cat_scaled)\n",
    "\n",
    "combined_distances = combine_distances_from_blocks(block_rois_raw, n_roi_all)\n",
    "\n",
    "distances_clusters = [[]]*len(block_rois)\n",
    "for i_block, block in enumerate(tqdm(block_rois)):\n",
    "    labels = block['db'].labels_\n",
    "    uci = block['labels_unique']\n",
    "    distances_clusters[i_block] = [[]]*len(uci)\n",
    "    for i_cid, cid in enumerate(uci):\n",
    "        roi_idx_cluster = np.where(labels == cid)[0]\n",
    "        roi_idx = block['idxCat_ROI_inOuterBlock'][roi_idx_cluster]\n",
    "        \n",
    "        distances_clusters[i_block][i_cid] = combined_distances[roi_idx][:,roi_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate statistics of distance matrices\n",
    "fn_dist_mean = lambda x: np.mean(x[np.triu_indices(x.shape[0], k=1)])\n",
    "fn_dist_std = lambda x: np.std(x[np.triu_indices(x.shape[0], k=1)])\n",
    "fn_dist_max = lambda x: np.max(x[np.triu_indices(x.shape[0], k=1)])\n",
    "\n",
    "dist_mean_all = [ [fn_dist_mean(distances_clusters[i_block][ii].toarray()) for ii in range(len(distances_clusters[i_block]))] for i_block in range(len(distances_clusters)) ]\n",
    "dist_std_all  = [ [fn_dist_std(distances_clusters[i_block][ii].toarray())  for ii in range(len(distances_clusters[i_block]))] for i_block in range(len(distances_clusters)) ]\n",
    "dist_max_all  = [ [fn_dist_max(distances_clusters[i_block][ii].toarray())  for ii in range(len(distances_clusters[i_block]))] for i_block in range(len(distances_clusters)) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8783a155",
   "metadata": {},
   "source": [
    "Plots for distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mean_all_cat = np.concatenate(dist_mean_all)\n",
    "dist_std_all_cat  = np.concatenate(dist_std_all)\n",
    "dist_max_all_cat  = np.concatenate(dist_max_all)\n",
    "\n",
    "# pair_columns = pd.DataFrame({\n",
    "#     \"mean\": dist_mean_all_cat,\n",
    "#     \"std\": dist_std_all_cat,\n",
    "#     \"max\": dist_max_all_cat,\n",
    "# })\n",
    "\n",
    "# plt.figure()\n",
    "# sns.pairplot(pair_columns, markers='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e47aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_stats = [\n",
    "    dist_mean_all_cat,\n",
    "    dist_std_all_cat,\n",
    "    dist_max_all_cat\n",
    "]\n",
    "fig, axs = plt.subplots(len(clust_stats))\n",
    "for ii, stat in enumerate(clust_stats):\n",
    "#     print(stat)\n",
    "    axs[ii].hist(stat,100, range=(0,0.0001))\n",
    "    axs[ii].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f99c0c",
   "metadata": {},
   "source": [
    "Set inclusion thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf15bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_properites = {\n",
    "    \"n_roi\": [block['sizes_clusters'] for block in block_rois],\n",
    "    \"clusters_fromUniqueSessions\": [block['cluster_sessions_isUnique'] for block in block_rois],\n",
    "    \"cluster_distance_mean\": dist_mean_all,\n",
    "    \"cluster_distance_std\": dist_std_all,\n",
    "    \"cluster_distance_max\": dist_std_all,\n",
    "}\n",
    "\n",
    "# cluster_inclusion_criteria_ranges = {\n",
    "#     \"n_roi\": (8,8),\n",
    "#     \"clusters_fromUniqueSessions\": (True,True),\n",
    "#     \"cluster_distance_mean\": (0,0.8),\n",
    "#     \"cluster_distance_std\": (0,0.3),\n",
    "#     \"cluster_distance_max\": (0,1.3),\n",
    "# }\n",
    "cluster_inclusion_criteria_ranges = {\n",
    "    \"n_roi\": (2,2),\n",
    "    \"clusters_fromUniqueSessions\": (True,True),\n",
    "    \"cluster_distance_mean\": (0,0.0000002),\n",
    "    \"cluster_distance_std\": (0,9),\n",
    "    \"cluster_distance_max\": (0,9),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006ea57",
   "metadata": {},
   "source": [
    "Assign cluster scores by inner blocks to each ROI. \\\n",
    "output (roi_cluster_properties) is a dictionary. 1 entry for each property. entry shape: (n_blocks, n_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b527070",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blocks = len(block_rois)\n",
    "n_properties = len(cluster_properites)\n",
    "\n",
    "# roi_labelFreqs = np.ones((len(block_rois), n_roi_all)) * np.nan # shape (n_blocks, n_roi_total)\n",
    "roi_cluster_properties = {key: np.ones((n_blocks, n_roi_all)) * np.nan for key,val in cluster_properites.items()}\n",
    "\n",
    "for i_block, block in enumerate(tqdm(block_rois)):\n",
    "    labels = block['db'].labels_\n",
    "    labels_unique = np.unique(labels)\n",
    "#     label_sizes = [list(labels).count(label) for label in labels_unique]\n",
    "    \n",
    "    bool_outer = block_rois[i_block]['boolCat_ROI_inOuterBlock']\n",
    "    idx_outer  = block_rois[i_block]['idxCat_ROI_inOuterBlock']\n",
    "    \n",
    "    bool_inner = np.concatenate(block_rois[i_block]['bool_ROI_inInnerBlock_allSesh'])\n",
    "    idx_inner = np.where(bool_inner)[0]\n",
    "    \n",
    "    for i_roi in range(n_roi_all): # for every ROI\n",
    "        if i_roi in idx_outer: # check if roi was in the outer frame\n",
    "            \n",
    "            if i_roi in idx_inner: # check if roi was in the inner frame\n",
    "                arg_outer = np.where(i_roi == idx_outer) # get argument in outer list of this roi\n",
    "                label = labels[arg_outer] # get the label of this roi in this block\n",
    "                arg_unique = np.where(labels_unique == label)[0][0] # get the idx/arg of of the labels_unique label\n",
    "                \n",
    "                \n",
    "                for i_property, (key, val) in enumerate(cluster_properites.items()):\n",
    "                    roi_cluster_properties[key][i_block, i_roi] = val[i_block][arg_unique]\n",
    "#                     print(val[i_block][arg_unique])\n",
    "#                     print(roi_cluster_properties[key][i_block, i_roi])\n",
    "#                     roi_cluster_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_in_range(array, range_vals):\n",
    "    return (array >= range_vals[0]) * (array <= range_vals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dad5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_cluster_inclusion_allProperties = {key: bool_in_range(roi_cluster_properties[key], cluster_inclusion_criteria_ranges[key]) for key,val in roi_cluster_properties.items()}\n",
    "roi_cluster_inclusion = np.stack(tuple(roi_cluster_inclusion_allProperties.values())).prod(0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecbc390f",
   "metadata": {},
   "source": [
    "roi_cluster_inclusion_allProperties"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e65714c",
   "metadata": {},
   "source": [
    "np.sum(roi_cluster_inclusion_allProperties['n_roi'].sum(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(roi_cluster_inclusion, aspect='auto', interpolation='antialiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ff278",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(roi_cluster_properties['cluster_distance_mean'], aspect='auto', interpolation='antialiased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd7ab1",
   "metadata": {},
   "source": [
    "- randomly choose rois from a list of all eligible ROIs\n",
    "- randomly choose a block that meet criteria for that roi,\n",
    "- find what other rois are a part of the cluster that it's in\n",
    "    - find what it's cluster label is for that block\n",
    "    - find other rois with that cluster label\n",
    "- assign that roi and all of the rois in that cluster a UCID\n",
    "- remove all those rois from the list to choose from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7edf2",
   "metadata": {},
   "source": [
    "- change step 2 to be 'best block'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8df78d5",
   "metadata": {},
   "source": [
    "UCIDs_rough = np.ones(n_roi_all, dtype=np.int64) * -1\n",
    "rois_included = np.where(roi_cluster_inclusion.sum(0) > 0)[0]\n",
    "list_eligible = copy.copy(rois_included)\n",
    "ucid_new = 0\n",
    "while len(list_eligible) > 0: # while there are still values that have not been deleted\n",
    "    idx_inList = random.choice(list_eligible)\n",
    "#     idx_inList = list_eligible[0]\n",
    "    block_toUse = random.choice(np.where(roi_cluster_inclusion[:,idx_inList] > 0)[0])\n",
    "    idx_in_block = np.where(block_rois[block_toUse]['idxCat_ROI_inOuterBlock'] == idx_inList)[0]\n",
    "    label = block_rois[block_toUse]['db'].labels_[idx_in_block]\n",
    "    idx_others_in_block = np.where(block_rois[block_toUse]['db'].labels_ == label)[0]\n",
    "    idx_others = block_rois[block_toUse]['idxCat_ROI_inOuterBlock'][idx_others_in_block]\n",
    "    UCIDs_rough[idx_others] = ucid_new\n",
    "    ucid_new += 1\n",
    "    \n",
    "    list_eligible = np.delete(list_eligible, np.where(np.isin(list_eligible,idx_others))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2978ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCIDs_rough = np.ones(n_roi_all, dtype=np.int64) * -1\n",
    "rois_included = np.where(roi_cluster_inclusion.sum(0) > 0)[0]\n",
    "list_eligible = copy.copy(rois_included)\n",
    "ucid_new = 0\n",
    "bunch_of_nans = np.ones(len(UCIDs_rough))*np.nan\n",
    "UCID_properties = {\n",
    "    'block':                 copy.copy(bunch_of_nans),\n",
    "    'idx_in_outerBlock':     copy.copy(bunch_of_nans),\n",
    "    'label_in_outerBlock':   copy.copy(bunch_of_nans),\n",
    "    \"n_roi_in_Cluster\":      copy.copy(bunch_of_nans),\n",
    "    \"cluster_distance_mean\": copy.copy(bunch_of_nans),\n",
    "    \"cluster_distance_std\":  copy.copy(bunch_of_nans),\n",
    "    \"cluster_distance_max\":  copy.copy(bunch_of_nans),\n",
    "    \"session\":               idx_roi_session,\n",
    "}\n",
    "while len(list_eligible) > 0: # while there are still values that have not been deleted\n",
    "    idx_inList = random.choice(list_eligible)\n",
    "#     idx_inList = list_eligible[0]\n",
    "    block_toUse = random.choice(np.where(roi_cluster_inclusion[:,idx_inList] > 0)[0])\n",
    "    idx_in_block = np.where(block_rois[block_toUse]['idxCat_ROI_inOuterBlock'] == idx_inList)[0]\n",
    "    label = block_rois[block_toUse]['db'].labels_[idx_in_block]\n",
    "    idx_others_in_block = np.where(block_rois[block_toUse]['db'].labels_ == label)[0]\n",
    "    idx_others = block_rois[block_toUse]['idxCat_ROI_inOuterBlock'][idx_others_in_block]\n",
    "    \n",
    "    if np.sum(np.isin(idx_others, np.where(UCIDs_rough>=0)[0]) > 0):\n",
    "        list_eligible = np.delete(list_eligible, np.where(np.isin(list_eligible, idx_inList))[0])\n",
    "        continue\n",
    "    \n",
    "    UCIDs_rough[idx_others] = ucid_new\n",
    "    ucid_new += 1\n",
    "    \n",
    "    list_eligible = np.delete(list_eligible, np.where(np.isin(list_eligible, idx_others))[0])\n",
    "    \n",
    "    \n",
    "    UCID_properties['block'][idx_others] = block_toUse\n",
    "    UCID_properties['idx_in_outerBlock'][idx_others] = idx_others_in_block\n",
    "    UCID_properties['label_in_outerBlock'][idx_others] = label\n",
    "    UCID_properties['n_roi_in_Cluster'][idx_others] = roi_cluster_properties['n_roi'][block_toUse][idx_others]\n",
    "    UCID_properties['cluster_distance_mean'][idx_others] = roi_cluster_properties['cluster_distance_mean'][block_toUse][idx_others]\n",
    "    UCID_properties['cluster_distance_std'][idx_others] = roi_cluster_properties['cluster_distance_std'][block_toUse][idx_others]\n",
    "    UCID_properties['cluster_distance_max'][idx_others] = roi_cluster_properties['cluster_distance_max'][block_toUse][idx_others]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c982c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCIDs = UCIDs_rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7113fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(UCIDs_rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_with_counts_outside_of_range(values, val_range, verbose=True):\n",
    "    unique_values = np.unique(values)\n",
    "    unique_counts = np.array([np.sum(values==val) for val in unique_values])\n",
    "    bad_outOfRange = unique_values[\n",
    "        np.logical_not(np.isin(\n",
    "            unique_counts,\n",
    "                np.arange(val_range[0], val_range[1]+1)\n",
    "        ))\n",
    "    ]\n",
    "    print(f'Found bad values: {bad_outOfRange}')\n",
    "    return bad_outOfRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46daf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of unique clusters: {len(np.unique(UCIDs_rough))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9baf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_UCIDs = values_with_counts_outside_of_range(UCIDs_rough, cluster_inclusion_criteria_ranges['n_roi'])\n",
    "UCIDs = copy.copy(UCIDs_rough)\n",
    "UCIDs[np.isin(UCIDs, bad_UCIDs)] = -1\n",
    "UCIDs = classification.squeeze_integers(UCIDs)\n",
    "UCID_properties['UCID'] = UCIDs\n",
    "values_with_counts_outside_of_range(UCIDs, cluster_inclusion_criteria_ranges['n_roi']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e97544",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_UCIDs = np.unique(UCIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99156da",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sessions = len(ROIs_aligned)\n",
    "n_roi_per_sesh\n",
    "bounds_idx_roi_per_sesh = np.concatenate([[0], np.cumsum(n_roi_per_sesh)])\n",
    "UCIDs_bySession = [UCIDs[bounds_idx_roi_per_sesh[ii]:bounds_idx_roi_per_sesh[ii+1]] for ii in range(n_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c0dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a UCID x session matrix (boolean)\n",
    "UCIDs_inSession = np.array([np.isin(unique_UCIDs, UCIDs_bySession[i_sesh]) for i_sesh in range(n_sessions)])\n",
    "if np.sum(UCIDs_inSession==0):\n",
    "    print(f'WARNING: Make sure you are okay with the fact that there are sessions where clusters are not present')\n",
    "if np.sum(UCIDs_inSession>1):\n",
    "    print(f'WARNING: Make sure you are okay with the fact that there are sessions where a single cluster has more than ROI in it')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a06c6",
   "metadata": {},
   "source": [
    "# Colored clusters image\n",
    "make an animation loop of an entire FOV looping through each session with all the ROIs. \\\n",
    "Each ROI in a cluster is given a distinct cluster color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480592d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Available properties to use as colormap:')\n",
    "display(list(UCID_properties.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f67674",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.get_cmap('rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e31dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plotting_helpers.rand_cmap(66, type='bright', first_color_black=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucid_toUse = unique_UCIDs[unique_UCIDs>0]\n",
    "cmap_property = 'UCID'\n",
    "\n",
    "vals_property = UCID_properties[cmap_property]\n",
    "vals_property_ranged = timeSeries.scale_between(vals_property, lower=0, upper=1.1, verbose=False)\n",
    "\n",
    "\n",
    "# cmaps = np.array([plt.get_cmap('Set3')(ii) for ii in vals_property_ranged])[:,:3]\n",
    "cmaps = np.array([cmap(ii) for ii in vals_property_ranged])[:,:3]\n",
    "\n",
    "FOV_all = []\n",
    "chunk_size = np.array([3, n_sessions, frame_height, frame_width]).prod()\n",
    "ROIs_csr = scipy.sparse.csr_matrix(scipy.sparse.vstack(ROIs_aligned))\n",
    "for ii, ucid in enumerate(tqdm(ucid_toUse)):\n",
    "   \n",
    "    idx_roi_ucid = np.where(UCIDs == ucid)[0]\n",
    "    colors = cmaps[idx_roi_ucid]\n",
    "    \n",
    "    n_ucid = len(idx_roi_ucid)\n",
    "    ROIs_scaled = ROIs_csr[idx_roi_ucid].multiply( 1 / ROIs_csr[idx_roi_ucid].max())\n",
    "    im_FOV_flat_tiled_color = scipy.sparse.vstack([ROIs_scaled.multiply(cmaps[idx_roi_ucid, i_color][:,None]) for i_color in range(3)])\n",
    "#     im_FOV_flat = ROIs_csr[idx_roi_ucid]\n",
    "#     im_FOV_flat = scipy.sparse.csr_matrix(scipy.sparse.vstack([ROIs_csr[ii] for ii in idx_roi_ucid]))\n",
    "#     im_FOV_flat_scaled = im_FOV_flat_tiled_color.multiply(1 / im_FOV_flat_tiled_color.max(1).toarray())\n",
    "    im_FOV_vector = im_FOV_flat_tiled_color.reshape((1,-1))\n",
    "#     im_FOV_flat_scaled_tiled_color = scipy.sparse.vstack([im_FOV_flat_scaled.multiply(colors[ii]) for ii in range(3)]).reshape((1, -1))\n",
    "#     im_FOV_flat_scaled_tiled_color = scipy.sparse.vstack([im_FOV_flat_scaled for ii in range(3)]).reshape((1, -1))\n",
    "\n",
    "    FOV_all.append(im_FOV_vector)\n",
    "\n",
    "FOV_all_sparseCOO = sparse.COO(scipy.sparse.vstack(FOV_all)).reshape((len(ucid_toUse), 3, n_sessions, frame_height, frame_width))\n",
    "\n",
    "FOV_all_sparseCOO_flat = FOV_all_sparseCOO.sum(0).transpose((1,2,3,0))\n",
    "\n",
    "FOV_all = FOV_all_sparseCOO_flat.todense()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1810659c",
   "metadata": {},
   "source": [
    "ucid_toUse = np.unique(UCIDs_Valerio)[np.unique(UCIDs_Valerio)>0]\n",
    "cmap_property = 'UCID'\n",
    "\n",
    "vals_property = UCID_properties[cmap_property]\n",
    "vals_property_ranged = timeSeries.scale_between(vals_property, lower=0, upper=1.1, verbose=False)\n",
    "\n",
    "\n",
    "# cmaps = np.array([plt.get_cmap('Set3')(ii) for ii in vals_property_ranged])[:,:3]\n",
    "cmaps = np.array([cmap(ii) for ii in vals_property_ranged])[:,:3]\n",
    "\n",
    "FOV_all = []\n",
    "chunk_size = np.array([3, n_sessions, frame_height, frame_width]).prod()\n",
    "ROIs_csr = scipy.sparse.csr_matrix(scipy.sparse.vstack(ROIs_aligned))\n",
    "for ii, ucid in enumerate(tqdm(ucid_toUse)):\n",
    "   \n",
    "    idx_roi_ucid = np.where(UCIDs_Valerio == ucid)[0]\n",
    "    colors = cmaps[idx_roi_ucid]\n",
    "    \n",
    "    n_ucid = len(idx_roi_ucid)\n",
    "    ROIs_scaled = ROIs_csr[idx_roi_ucid].multiply( 1 / ROIs_csr[idx_roi_ucid].max())\n",
    "    im_FOV_flat_tiled_color = scipy.sparse.vstack([ROIs_scaled.multiply(cmaps[idx_roi_ucid, i_color][:,None]) for i_color in range(3)])\n",
    "#     im_FOV_flat = ROIs_csr[idx_roi_ucid]\n",
    "#     im_FOV_flat = scipy.sparse.csr_matrix(scipy.sparse.vstack([ROIs_csr[ii] for ii in idx_roi_ucid]))\n",
    "#     im_FOV_flat_scaled = im_FOV_flat_tiled_color.multiply(1 / im_FOV_flat_tiled_color.max(1).toarray())\n",
    "    im_FOV_vector = im_FOV_flat_tiled_color.reshape((1,-1))\n",
    "#     im_FOV_flat_scaled_tiled_color = scipy.sparse.vstack([im_FOV_flat_scaled.multiply(colors[ii]) for ii in range(3)]).reshape((1, -1))\n",
    "#     im_FOV_flat_scaled_tiled_color = scipy.sparse.vstack([im_FOV_flat_scaled for ii in range(3)]).reshape((1, -1))\n",
    "\n",
    "    FOV_all.append(im_FOV_vector)\n",
    "\n",
    "FOV_all_sparseCOO = sparse.COO(scipy.sparse.vstack(FOV_all)).reshape((len(ucid_toUse), 3, n_sessions, frame_height, frame_width))\n",
    "\n",
    "FOV_all_sparseCOO_flat = FOV_all_sparseCOO.sum(0).transpose((1,2,3,0))\n",
    "\n",
    "FOV_all = FOV_all_sparseCOO_flat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b46925",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOV_all_noClip = copy.copy(FOV_all)\n",
    "FOV_all_noClip[FOV_all_noClip>1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57658168",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_helpers.play_video_cv2(FOV_all_noClip*255, frameRate=3, \n",
    "#                                 save_path='/home/rich/Desktop/test_harnett_distal_20220123.avi'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9317c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "imshow_FOV = ax.imshow(FOV_all_noClip[0], interpolation='none')\n",
    "\n",
    "def update(i_frame = 0):\n",
    "    fig.canvas.draw_idle()\n",
    "    imshow_FOV.set_data(FOV_all_noClip[i_frame])\n",
    "\n",
    "\n",
    "interact(update, i_frame=widgets.IntSlider(min=0, max=FOV_all.shape[0]-1, step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0d064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4fda008",
   "metadata": {},
   "source": [
    "outputs:\n",
    "`UCIDs`\n",
    "`UCIDs_bySession`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0566d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_helpers.simple_save(\n",
    "    {\n",
    "    \"UCIDs\": UCIDs,\n",
    "    \"UCIDs_bySession\": UCIDs_bySession,\n",
    "    },\n",
    "    filename=dir_save / 'UCIDs_20220225.pkl'\n",
    "#     filename='/media/rich/bigSSD/analysis_data/mouse 2_6/multiday_alignment/UCIDs.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc08fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781819d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "d9092374",
   "metadata": {},
   "source": [
    "ROIMatch = scipy.io.loadmat('/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/20220117_email/ROIMatch.mat')['RoiMatch4Fissa'] -1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53240482",
   "metadata": {},
   "source": [
    "UCIDs_bySession_Valerio = [np.ones_like(UCIDs_bySession[ii], dtype=np.int64)*-1 for ii in range(len(UCIDs_bySession))]\n",
    "\n",
    "for ii in range(ROIMatch.shape[1]):\n",
    "    UCIDs_bySession_Valerio[ii][ROIMatch[:,ii]] = np.arange(ROIMatch.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8257e4e0",
   "metadata": {},
   "source": [
    "UCIDs_Valerio = np.concatenate(UCIDs_bySession_Valerio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c0520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb092b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4203725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0646429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a63c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f3c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
